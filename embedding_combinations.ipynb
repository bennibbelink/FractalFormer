{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780020eb-32cc-4cf5-bd24-9d824f936aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99d14d41-c829-4bdd-8c6f-50dcf075b967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3607, -0.4976],\n",
       "        [-1.2192,  2.2165],\n",
       "        [ 0.8557, -0.5750],\n",
       "        [ 0.0025, -0.8335]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = 4\n",
    "d = 2\n",
    "E = torch.randn(v,d, requires_grad=True)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb088b1d-a2c4-4583-8bd7-712d87d68c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangular(n):\n",
    "    return n*(n+1)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2283959f-a531-49da-b712-eb25b98bed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "v2 = triangular(v)\n",
    "print(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aacb34c-1cd4-4528-a14e-a3e491ace685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E2 = torch.zeros((int(v2), d), requires_grad=False)\n",
    "E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a991e655-e5e1-4665-a586-3e7b649cc1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "j: 0\n",
      "vec: tensor([-0.3607, -0.4976], grad_fn=<UnbindBackward0>)\n",
      "expanded vec: torch.Size([4, 2])\n",
      "tensor([[-0.3607, -0.4976],\n",
      "        [-0.3607, -0.4976],\n",
      "        [-0.3607, -0.4976],\n",
      "        [-0.3607, -0.4976]], grad_fn=<ExpandBackward0>)\n",
      "spliced 2nd matrix: torch.Size([4, 2])\n",
      "tensor([[-0.3607, -0.4976],\n",
      "        [-1.2192,  2.2165],\n",
      "        [ 0.8557, -0.5750],\n",
      "        [ 0.0025, -0.8335]], grad_fn=<SliceBackward0>)\n",
      "[0:4,:]\n",
      "E2: torch.Size([10, 2])\n",
      "tensor([[-0.7215, -0.9952],\n",
      "        [-1.5799,  1.7189],\n",
      "        [ 0.4949, -1.0726],\n",
      "        [-0.3582, -1.3311],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "i: 1\n",
      "j: 4\n",
      "vec: tensor([-1.2192,  2.2165], grad_fn=<UnbindBackward0>)\n",
      "expanded vec: torch.Size([3, 2])\n",
      "tensor([[-1.2192,  2.2165],\n",
      "        [-1.2192,  2.2165],\n",
      "        [-1.2192,  2.2165]], grad_fn=<ExpandBackward0>)\n",
      "spliced 2nd matrix: torch.Size([3, 2])\n",
      "tensor([[-1.2192,  2.2165],\n",
      "        [ 0.8557, -0.5750],\n",
      "        [ 0.0025, -0.8335]], grad_fn=<SliceBackward0>)\n",
      "[4:7,:]\n",
      "E2: torch.Size([10, 2])\n",
      "tensor([[-0.7215, -0.9952],\n",
      "        [-1.5799,  1.7189],\n",
      "        [ 0.4949, -1.0726],\n",
      "        [-0.3582, -1.3311],\n",
      "        [-2.4383,  4.4329],\n",
      "        [-0.3635,  1.6414],\n",
      "        [-1.2166,  1.3829],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "i: 2\n",
      "j: 7\n",
      "vec: tensor([ 0.8557, -0.5750], grad_fn=<UnbindBackward0>)\n",
      "expanded vec: torch.Size([2, 2])\n",
      "tensor([[ 0.8557, -0.5750],\n",
      "        [ 0.8557, -0.5750]], grad_fn=<ExpandBackward0>)\n",
      "spliced 2nd matrix: torch.Size([2, 2])\n",
      "tensor([[ 0.8557, -0.5750],\n",
      "        [ 0.0025, -0.8335]], grad_fn=<SliceBackward0>)\n",
      "[7:9,:]\n",
      "E2: torch.Size([10, 2])\n",
      "tensor([[-0.7215, -0.9952],\n",
      "        [-1.5799,  1.7189],\n",
      "        [ 0.4949, -1.0726],\n",
      "        [-0.3582, -1.3311],\n",
      "        [-2.4383,  4.4329],\n",
      "        [-0.3635,  1.6414],\n",
      "        [-1.2166,  1.3829],\n",
      "        [ 1.7113, -1.1500],\n",
      "        [ 0.8582, -1.4086],\n",
      "        [ 0.0000,  0.0000]], grad_fn=<CopySlices>)\n",
      "i: 3\n",
      "j: 9\n",
      "vec: tensor([ 0.0025, -0.8335], grad_fn=<UnbindBackward0>)\n",
      "expanded vec: torch.Size([1, 2])\n",
      "tensor([[ 0.0025, -0.8335]], grad_fn=<ExpandBackward0>)\n",
      "spliced 2nd matrix: torch.Size([1, 2])\n",
      "tensor([[ 0.0025, -0.8335]], grad_fn=<SliceBackward0>)\n",
      "[9:10,:]\n",
      "E2: torch.Size([10, 2])\n",
      "tensor([[-0.7215, -0.9952],\n",
      "        [-1.5799,  1.7189],\n",
      "        [ 0.4949, -1.0726],\n",
      "        [-0.3582, -1.3311],\n",
      "        [-2.4383,  4.4329],\n",
      "        [-0.3635,  1.6414],\n",
      "        [-1.2166,  1.3829],\n",
      "        [ 1.7113, -1.1500],\n",
      "        [ 0.8582, -1.4086],\n",
      "        [ 0.0051, -1.6671]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i, vec in enumerate(E):\n",
    "    print(f\"i: {i}\")\n",
    "    print(f\"j: {j}\")\n",
    "    print(f\"vec: {vec}\")\n",
    "    print(f\"expanded vec: {vec.expand(v-i,d).shape}\\n{vec.expand(v-i,d)}\")\n",
    "    print(f\"spliced 2nd matrix: {E[i:,:].shape}\\n{E[i:,:]}\")\n",
    "    print(f\"[{j}:{j+v-i},:]\")\n",
    "    E2[j:j+v-i,:] += E[i,:].expand(v-i,d) + E[i:,:]\n",
    "    print(f\"E2: {E2.shape}\\n{E2}\")\n",
    "    j += v-i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82515f03-6417-41c3-b930-12e286042d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combination_embedding(E):\n",
    "    v, d = E.shape\n",
    "    E2 = torch.zeros((v*(v+1)//2, d), requires_grad=False)\n",
    "    j = 0\n",
    "    for i, vec in enumerate(E):\n",
    "        E2[j:j+v-i,:] += E[i,:].expand(v-i,d) + E[i:,:]\n",
    "        j += v-i\n",
    "\n",
    "    return E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "135337f9-e81f-4289-94b1-f4bd95edb96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7805,  0.8609,  0.6080, -0.3149],\n",
      "        [-0.6034, -0.0507,  1.6488,  0.5085],\n",
      "        [-0.5193, -0.5827, -0.9297, -0.2837],\n",
      "        [ 1.7073, -0.7053,  0.2405,  0.1730],\n",
      "        [-0.6074, -0.8870, -1.2033,  0.1397],\n",
      "        [-1.6504,  0.1580, -0.7893,  0.4016],\n",
      "        [ 0.0581, -1.0727, -0.1236,  0.3214],\n",
      "        [-0.2835, -0.3713,  0.6168,  1.6662],\n",
      "        [ 0.1200,  0.1332, -0.1708, -0.7695],\n",
      "        [ 0.0816, -0.1551, -0.2668, -0.1468],\n",
      "        [ 0.0272, -1.1563, -0.8942,  0.1306],\n",
      "        [ 1.5876, -1.0553,  1.5033,  0.2858],\n",
      "        [ 2.1168, -0.2589, -1.3682, -0.0186],\n",
      "        [-1.1656,  1.6409, -0.7500,  0.6620],\n",
      "        [ 0.6155,  0.0848, -1.3865,  1.1657],\n",
      "        [ 0.9159, -1.6951,  0.8123,  0.1749],\n",
      "        [-2.1635,  0.2846, -1.4025,  0.5925],\n",
      "        [ 1.6073, -1.5286, -2.1382, -1.4981],\n",
      "        [-0.9451, -1.0817,  0.4746, -1.2434],\n",
      "        [ 1.7261, -0.3090,  0.3621, -0.1013],\n",
      "        [-1.7278, -0.0735,  0.3864, -0.2759],\n",
      "        [ 0.7784, -0.7094, -0.2681, -0.0650],\n",
      "        [ 0.7606,  0.7444,  0.1704, -0.8427],\n",
      "        [-1.6031, -0.2416, -2.1436,  0.7358],\n",
      "        [ 1.3386, -0.1946,  0.6252,  0.1255],\n",
      "        [-2.2402,  1.0054,  0.7445, -0.5155],\n",
      "        [ 1.2307,  1.1554,  1.1077,  1.2455],\n",
      "        [-0.9877,  1.8420, -0.2862,  1.3646],\n",
      "        [-2.0283, -1.5051, -1.3662, -0.6257],\n",
      "        [ 0.2533, -0.0977, -0.6583,  0.1686],\n",
      "        [-0.0104, -1.0233, -0.5664,  0.0826],\n",
      "        [ 0.3080, -1.0916, -0.2015, -1.5004],\n",
      "        [-1.3321, -0.9161,  0.2754,  0.1433],\n",
      "        [ 1.3618, -0.1886,  0.2844,  1.1024],\n",
      "        [-0.7786, -0.2519, -0.6075,  1.0645],\n",
      "        [ 0.2150,  0.7724,  0.1350, -0.9771],\n",
      "        [ 0.5563,  0.9764,  1.9788, -0.3132],\n",
      "        [-1.6280,  0.5283, -1.0302, -0.4879],\n",
      "        [-0.7426, -1.9828, -1.5928, -0.7481],\n",
      "        [ 0.6563,  1.5917, -0.7015,  0.6282],\n",
      "        [ 1.4875,  1.2681, -1.8179,  1.5193],\n",
      "        [ 1.2857, -0.2068, -0.6441, -0.7951],\n",
      "        [ 2.9007,  1.0379, -0.0662, -1.0505],\n",
      "        [ 0.3955, -0.0164, -0.0510, -0.1889],\n",
      "        [-0.6582, -2.1713, -0.5974,  1.1743],\n",
      "        [-1.8955, -0.9169,  1.4674, -0.4366],\n",
      "        [-0.3681,  1.0007, -0.8051,  0.3190],\n",
      "        [-0.1620, -2.1085,  0.2272, -1.0198],\n",
      "        [-0.2235, -0.8557, -0.6798,  0.9413],\n",
      "        [-0.3228, -0.9564, -2.3639, -0.1801],\n",
      "        [-2.2334,  1.6472, -1.4154,  1.0663],\n",
      "        [ 0.1445,  0.4403, -1.0027, -0.1116],\n",
      "        [-0.7870, -0.4706,  2.4633,  0.4312],\n",
      "        [-1.0623, -0.0518, -1.8828,  2.4449],\n",
      "        [ 0.2766,  0.0834, -0.3895, -1.5095],\n",
      "        [ 1.2264,  0.8473,  0.4020,  1.3231],\n",
      "        [-1.1365,  0.3156,  0.8892, -0.5257],\n",
      "        [-0.4308,  0.4873,  0.1928, -1.4874],\n",
      "        [-0.5943,  1.1388,  0.1143, -1.0264],\n",
      "        [-1.3006,  0.8559, -0.2998,  2.9206],\n",
      "        [ 1.6728, -0.1369, -0.9557, -0.7193],\n",
      "        [-1.3318,  0.4638,  0.9847,  2.3853],\n",
      "        [ 1.5798, -2.2131, -0.1175,  2.2267],\n",
      "        [ 0.5508, -2.0909, -0.5291,  0.5115],\n",
      "        [-1.6282,  0.4524, -0.1712,  1.0813]])\n",
      "2145\n"
     ]
    }
   ],
   "source": [
    "test = torch.randn(65,4)\n",
    "print(test)\n",
    "E2 = combination_embedding(test)\n",
    "print(E2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d436b4e2-a585-4305-a631-adacfd7fe2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2301585\n"
     ]
    }
   ],
   "source": [
    "E3 = combination_embedding(E2)\n",
    "print(E3.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8eb3a-49db-4aba-b62d-d66aa7d9c091",
   "metadata": {},
   "source": [
    "I'm thinking maybe i can start off with some absurdly huge supertoken setup made from bytes and then use a method to trim it down to more interesting token combinations like in that one paper i just read [tokenization is more than compression](https://arxiv.org/pdf/2402.18376.pdf) to make the size actually manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf40bd8-2e0a-4167-9f09-51d2efb70fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
